杨争峰： 针对图像识别神经网络的对抗样本生成研究

绪论：
深度神经网络： 神经网络模拟大脑神经元通过突触建立连接、传递信息的过程，建立神经网络节点并按一定结构进行连接，通过调节连接处的权重控制节点间信息传递的效率，
并且在节点上进行激活操作，对接收的信息进行加工。在一定范围内，增加神经网络层数可以提高网络准确性，这种层数较多的神经网络叫做深度神经网络，一般在五层以上，
有一些网络可以达到几百层甚至上千层。

将精心设计得到的微小扰动添加到样本数据中再输入神经网络，可以在人类察觉不到的情况下使已经训练好的网络模型给出完全不同的输出结果，
从而达到攻击效果，被攻击的模型不仅会发生分类错误，还会以很高的置信度输出错误预测结果。这一现象被称作对抗攻击（adversarial attack）现象，
这种能够造成攻击效果的小扰动被称作对抗扰动（adversarial perturbation），将对抗扰动添加到原始样本上会形成一个新的样本，
将新生成的样本输入神经网络中会得到错误的分类结果，这种使神经网络分类错误的新样本被称作对抗样本

为提高神经网络的安全性，研究人员对于对抗攻击现象展开了一系列探索和研究，研究内容可以分为攻击方法 [23, 31-35] 和防御方法 [36-41] 两部分。
攻击方法指的是通过生成对抗扰动对神经网络模型进行攻击的方法，防御方法指的是通过修正对抗样本、修改网络结构等方式避免模型受到对抗攻击，从而提高模型鲁棒性的方法。

关于特定对抗扰动生成：在设计生成特定对抗扰动时，一个重要的目标就是使对抗扰动不易被人眼察觉。目前大部分方法都是通过减小扰动的 lp范数来降低人眼感知度的，
并且已经可以得到范数很小的扰动。